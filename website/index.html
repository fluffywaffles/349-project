<style>body { max-width: 800px; margin: 0 auto; font-size: 18px }
h1, h2, h3, h4, h5 { text-align: center }
img { max-height: 500px; max-width: 100%; padding: 20px 0; }
figcaption { font-style: italic; font-size: 14px; }
</style><h1>Generating Game Reviews</h1><h3>Michael Horst, Jordan Timmerman, Agam Gupta, Upasna Madhok</h3><h5>Contact: <a href='mailto:MichaelHorst2016@u.northwestern.edu'>
MichaelHorst2016@u.northwestern.edu</a></h5><h5>EECS 349: Machine Learning <br> Northwestern University, Spring 2016</h5><h3>Motivation</h3><p>Steam (an online gaming platform that provides users with installation and
automatic updating of games in addition to many other features) has a database
of games having tens of thousands of reviews, not all of which are high
quality/useful and a lot of which are similar to one another. We think
generating reviews that can accurately emulate the best reviews on Steam will
give prospective buyers more information, especially if the model can generate
high-quality reviews of a game based upon a data set consisting of mixed quality
reviews. This will save potential customers time in evaluating whether a game is
worth purchasing.</p><h3>Solution</h3><p>We focused on two different machine learning solutions to generate helpful
reviews: character-level Recurrent Neural Networks (char-RNN) and Hidden
Markov Models (HMM). char-RNNs train on a chunk of text and learn to generate
new text character by character, whereas HMMs calculate transition
probabilities between n-grams (sequences of n words) for training, and then
can be sampled to generate text. To train char-RNN, we used text files
containing review content ranging from 300 kB to 15 mB, epochs ranging from
10-50 (more for smaller data sets) and hidden units ranging from 48-128 (more
for larger data sets). We then generated samples with temperatures ranging
from 0.3 to 0.6. For HMMs, we wrote generic model generation and sampling
scripts and trained multiple models. First, we tried taking the top 50 most
helpful reviews for a specific game and creating bigrams and trigrams. Then,
we tried taking a sample of 15000 out of the set of top 50 most helpful
reviews from every game in the data set of 8145 games, and created models
with bigrams, trigrams, all the way up to 10-grams, and tested the output.
10-gram models generated almost verbatim copies of very long reviews from the
data set. 3-5-gram models generated coherent, but sometimes confused, reviews
that were fairly original but which might talk about one game one paragraph,
and another game in the next - and mention each by name. Results were better
when training data was limited to a set of reviews for a particular game,
although the results were often passable even with the large training set.</p><h3>Testing/Training</h3><p>The dataset of the games was extracted from the steam API (scraping from
<a
href='http://steamcommunity.com/app/{gameid}/homecontent'>
http://steamcommunity.com/app/{gameid}/homecontent
</a> URLs). This HTML content
was then scraped and processed using a programmatic headless web browser
(CasperJS) to extract information such as 'reviewerUsername',
'reviewerDisplayName', 'reviewerProductsCount', 'reviewText', 'recommended',
'hoursPlayed', 'commentsCount' -  for every review of every game title. The
reviews were saved as csvs, each csv containing all reviews for a particular
game. To train the Hidden Markov Model we used the top 50 most helpful
reviews from each of 8145 games; whereas for training the RNN, we used the
top 1000 most helpful reviews for a single game. Since we are using text
generation algorithms, we donâ€™t have a test set to compare our models
against. </p><h3>Key Results</h3><p>We considered success to be when the generated review makes sense and has a
positive or negative sentiment to it. We compare this tone with the general
sentiment of the review (provided in the training dataset). If the
sentiments match then we achieve success. This was done for multiple games.</p><p><u>HMM</u>: The results from the Hidden Markov Models turned out very well. In
particular, they were clear, grammatically plausible and (usually) made
sense contextually as reviews. (See below for an example of a review
generated by HMM.) Given the quality of these generated reviews we have
concluded that HMM works as a better model for generating game reviews from
a corpus of existing reviews. </p><figure><img src="./hmm-general.png"/><figcaption>Figure 1. One of our best 4-gram HMM model generated reviews,
generated from a text dump of 15,000 of the top 50 most helpful reviews
sampled from across 8,145 games.</figcaption></figure><p> 
Reviews could be generated for a specific game if it had enough
reviews already, or could be generated from a set of reviews across all
games. See below for example reviews generated for Call of Duty: World at
War from its top 50 reviews.</p><figure><img src="./hmm-single-game.png"/><figcaption>Figure 2. Reviews generated for Call of Duty: World at War from existing
reviews for that game using 4-gram HMM.</figcaption></figure><p>HMM also would sometimes mimic features from reviews, such as pro/con bullet
lists. It also often happened, with general reviews (not game-specific) that
more than one specific game would be mentioned by name in a review - so the
model sometimes got confused.</p><figure><img src="./hmm-features.png"/><figcaption>Figure 3. A review showcasing both pro/con list generation and cross-game
confusion in output of a 4-gram HMM model.</figcaption></figure><p><u>Char-RNN Model</u>: We tried a couple of games on the charRNN model and compared
the resulting review's sentiment to the original one. We could not get a
good accuracy for the games that we tested on, as the tone of the review
could not be identified (in the interest of time, we only tested our model
on a few reviews). The perplexity of the model for these games was roughly
8%. When testing on a much larger test set of the top 3 reviews of every
game (roughly 15 MB of text) the resultant reviews were higher quality, but
had no relation to any particular game. (See below for an example result.)</p><figure><img src="./char-rnn.png"/><figcaption>Figure 4. One of our best Char-RNN reviews for a single game, the top
reviews having been multiplied to increase their weight.</figcaption></figure><h3>Links</h3><p><a href='https://github.com/skorlir/349-project'>GitHub</a></p><p><a href='./FinalReport.pdf'>PDF of Full Report</a></p>